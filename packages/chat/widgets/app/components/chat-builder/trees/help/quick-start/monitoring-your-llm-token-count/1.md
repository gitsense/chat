<!--
Component: Quick Start - Monitoring Your LLM Token Count
Block-UUID: 4f4a0f09-17b9-44af-8217-7c4bb0d771a9
Parent-UUID: N/A
Version: 1.0.0
Description: Quick start guide for monitoring LLM token count to manage context and optimize costs.
Language: Markdown
Created-at: 2025-07-29T23:08:24.529Z
Authors: Gemini 2.5 Flash Thinking (v1.0.0)
-->


> GitSense Chat Help: Quick Start / Monitoring Your LLM Token Count

## Monitoring Your LLM Token Count

Keep track of the estimated token count to manage the AI's context window, avoid diluted responses, and optimize API costs.

**How to Do It:**

Check the **"Tokens" count** in the **"Overview" section** of the right sidebar. This large number shows the estimated token usage in your conversation, acting like a "tachometer" for your LLM.

![Token Counter]({{base-uri}}/monitor-your-llm-token-count-bordered.png)
